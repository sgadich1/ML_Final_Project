Denoising Datasets used in our experiments
-----

### Dataset download
Due to the limitation of repo size, we upload the datasets to Google Drive. You can **download the datasets** [here](https://drive.google.com/file/d/1USSxcGvteWxtyZh4P3X3cBfxD2ZRieNX/view?usp=share_link).


#### RGB Natural Images (ImageNet)
We construct the RGB natural image dataset from the ImageNet ILSVRC2012 Validation dataset that consists of 50,000 natural images. In particular, we follow [Noise2Self](https://arxiv.org/abs/1901.11365) to generate noisy images by applying a combination of three types of noises to the clear images. The noises are Poisson noise (λ = 30), additive Gaussian noise (μ = 0, σ = 60) and Bernoulli noise (p = 0.2). To be consistent to Noise2Self, we randomly crop 60,000 patches of size 128 x 128 from the first 20,000 images in ILSVRC2012 Val to construct the training dataset. Additional two sets of 1,000 images from ILSVRC2012 Val are used for validation and testing, respectively.

The code to generate the noisy images can be found in `Denoising_Data/ImageNet/generate_noisy.ipynb`.

#### Hand-written Chinese Character Images (Hanzi)
We generate the HànZì dataset with the code provided by [Noise2Self](https://arxiv.org/abs/1901.11365). The dataset is constructed with 13029 Chinese characters and consists of 78174 noisy images of size 64 x 64, where each noisy image is generated by applying Gaussian noise (σ = 0.7) and Bernoulli noise to a clear Chinese character image. Among the 78174 noisy images, 90% are used for training and validation, and the rest 10% are for testing.

The code to generate the noisy images is available at [this repo](https://github.com/batson/hanzi).
